{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPC2RJ/70p0wGY2rALyAXF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berkeyagizkiliccii/FSWeb-S2G4-JavaScript-tekrar/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "w4Gq04XZyHby"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Step 1: Load Libraries and Dataset\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve\n",
        ")\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# featurelerin isimleri (education, marraige vb 2. satırda olduğu için headerı 1 ayarladık yani ilk satırı görmezden geldik)\n",
        "df = pd.read_excel(\"default of credit card clients.xls\", header=1)\n",
        "\n",
        "# ID sütununu veri olarak işlevsiz olduğu için attık\n",
        "#kopya oluşturmadan orijinal data üzerinde değişiklik yapıyoruz inplace=true\n",
        "\n",
        "if \"ID\" in df.columns:\n",
        "    df.drop(columns=[\"ID\"], inplace=True)\n",
        "\n",
        "# y nin ismi \"default payment next month\" olduğu için kısaltıp default dedik. 1 ödeme yapmayacak 0 yapacak\n",
        "df.rename(columns={\"default payment next month\": \"DEFAULT\"}, inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 2: Preprocessing\n",
        "# ==========================================\n",
        "\n",
        "# Sütunların herhangi birinde eksik değer var mı baktık\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Education için kaç tane benzersiz category var\n",
        "print(\"\\nEDUCATION value counts (before cleaning):\")\n",
        "print(df[\"EDUCATION\"].value_counts())\n",
        "\n",
        "# Marriage için kaç tane benzersiz category var\n",
        "print(\"\\nMARRIAGE value counts (before cleaning):\")\n",
        "print(df[\"MARRIAGE\"].value_counts())\n",
        "\n",
        "# 1=Lisansüstü 2=üniversite 3=Lise. 0 5 6 algoritmayı bozmasın diye other olarak adlandırdım\n",
        "df[\"EDUCATION\"] = df[\"EDUCATION\"].replace({0: 4, 5: 4, 6: 4})\n",
        "\n",
        "# 1=evli 2=bekar bunlar 0 da vardı bunu other olarak adlandırdım\n",
        "df[\"MARRIAGE\"] = df[\"MARRIAGE\"].replace({0: 3})\n",
        "\n",
        "#cleaningden sonra kaç benzersiz var baktım\n",
        "print(\"\\nEDUCATION value counts (after cleaning):\")\n",
        "print(df[\"EDUCATION\"].value_counts())\n",
        "\n",
        "#cleaningden sonra kaç benzersiz var baktım\n",
        "print(\"\\nMARRIAGE value counts (after cleaning):\")\n",
        "print(df[\"MARRIAGE\"].value_counts())\n",
        "\n",
        "# target olarak imbalanceye bakarız. 0 ve 1lerin sayısına\n",
        "print(\"\\nTarget distribution (counts):\")\n",
        "print(df[\"DEFAULT\"].value_counts())\n",
        "\n",
        "# target olarak imbalanceye bakarız. 0 ve 1lerin oranına(normalize true)\n",
        "print(\"\\nTarget distribution (ratios):\")\n",
        "print(df[\"DEFAULT\"].value_counts(normalize=True))\n",
        "#imbalance var 0=0.7788 ödeme yapanlar 1=0.2212 ödeme yapmayanlar\n",
        "#yani accuracy yetersiz kalır çünkü dataset imbalance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXp-M8FYOdc0",
        "outputId": "fbedff53-4349-44e8-84ad-3cb396a93f41"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n",
            "LIMIT_BAL    0\n",
            "SEX          0\n",
            "EDUCATION    0\n",
            "MARRIAGE     0\n",
            "AGE          0\n",
            "PAY_0        0\n",
            "PAY_2        0\n",
            "PAY_3        0\n",
            "PAY_4        0\n",
            "PAY_5        0\n",
            "PAY_6        0\n",
            "BILL_AMT1    0\n",
            "BILL_AMT2    0\n",
            "BILL_AMT3    0\n",
            "BILL_AMT4    0\n",
            "BILL_AMT5    0\n",
            "BILL_AMT6    0\n",
            "PAY_AMT1     0\n",
            "PAY_AMT2     0\n",
            "PAY_AMT3     0\n",
            "PAY_AMT4     0\n",
            "PAY_AMT5     0\n",
            "PAY_AMT6     0\n",
            "DEFAULT      0\n",
            "dtype: int64\n",
            "\n",
            "EDUCATION value counts (before cleaning):\n",
            "EDUCATION\n",
            "2    14030\n",
            "1    10585\n",
            "3     4917\n",
            "5      280\n",
            "4      123\n",
            "6       51\n",
            "0       14\n",
            "Name: count, dtype: int64\n",
            "\n",
            "MARRIAGE value counts (before cleaning):\n",
            "MARRIAGE\n",
            "2    15964\n",
            "1    13659\n",
            "3      323\n",
            "0       54\n",
            "Name: count, dtype: int64\n",
            "\n",
            "EDUCATION value counts (after cleaning):\n",
            "EDUCATION\n",
            "2    14030\n",
            "1    10585\n",
            "3     4917\n",
            "4      468\n",
            "Name: count, dtype: int64\n",
            "\n",
            "MARRIAGE value counts (after cleaning):\n",
            "MARRIAGE\n",
            "2    15964\n",
            "1    13659\n",
            "3      377\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target distribution (counts):\n",
            "DEFAULT\n",
            "0    23364\n",
            "1     6636\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target distribution (ratios):\n",
            "DEFAULT\n",
            "0    0.7788\n",
            "1    0.2212\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# step 3)Split dataset 70 15 15\n",
        "# ==========================================\n",
        "\n",
        "X = df.drop(\"DEFAULT\", axis=1) #son sütun(target hariç xe ata)\n",
        "y = df[\"DEFAULT\"] #targeti belirle\n",
        "\n",
        "# 70 30 ilk bölme\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "#straify=y verdik çünkü imbalance durumun veri seti bölerken de aynı oranda korunmasını istedik\n",
        "# 30u 15 15 bölme\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eDf4mVeOOgyh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 4: Feature Scaling\n",
        "# ==========================================\n",
        "#büyük ölçekli featureler (LIMIT_BAL=500000) küçük ölçekli featureleri (age=30) ezmesin diye scaling yapıyoruz\n",
        "scaler = StandardScaler()\n",
        "x_train_s=scaler.fit_transform(X_train)\n",
        "#trainlerde fit yapıyoruz ama val ve testte fit yapmıyoruz çünkü test datasını öğrensin istemiyoruz\n",
        "X_val_s   = scaler.transform(X_val)\n",
        "X_test_s  = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "LIGXy4wQOktx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 5: Baseline Model – Logistic Regression\n",
        "# ==========================================\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42) #default iterasyon sayısı 100 dür 100 tekrarda öğrenememe\n",
        "#ihtimaline karşılık max tekrar sayısını 1000 yaptık\n",
        "log_reg.fit(X_train_s, y_train)\n",
        "\n",
        "y_pred_log = log_reg.predict(X_test_s) #tahminleri (0 mı 1 mi y ye kaydederiz)\n",
        "y_prob_log = log_reg.predict_proba(X_test_s)[:, 1]\n",
        "#predic_proba[[0.90, 0.10], [0.35, 0.65], gibi listeler döndürür\n",
        "#1. eleman default yapmama(ödeme) ihtimali 2.eleman default yapma(ödememe) ihtimali\n",
        "#buradan 2. sütunu yani default ödeme yapmama oranlarını alıp y_prob_log'a kaydediyoruz\n",
        "#roc-auc için bu lazım\n",
        "\n",
        "acc_log  = accuracy_score(y_test, y_pred_log)\n",
        "prec_log = precision_score(y_test, y_pred_log)\n",
        "rec_log  = recall_score(y_test, y_pred_log)\n",
        "f1_log   = f1_score(y_test, y_pred_log)\n",
        "auc_log  = roc_auc_score(y_test, y_prob_log)\n",
        "\n",
        "print(\"\\n Logistic Regression – Test Performance\")\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "print(f\"Accuracy : {acc_log:}\") #model başarısı (imbalance dataset olduğı için yetersiz)\n",
        "print(f\"Precision: {prec_log:}\") #ödeyecek dediklerinin nekadarı gerçekten ödeyecek\n",
        "print(f\"Recall   : {rec_log:}\") #ödemeyecekler ödeyecek gözüktü mü\n",
        "print(f\"F1-Score : {f1_log:}\") #pre rec harmonik ortalama\n",
        "print(f\"ROC-AUC  : {auc_log:.4f}\") #sınıfları ayırma başarısını gösterir 0.7 ortalama başarılı\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aLrA5WxOodc",
        "outputId": "cd916af5-05c2-4e07-f3f0-8fd264fae19e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Logistic Regression – Test Performance\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.97      0.89      3504\n",
            "           1       0.70      0.23      0.35       996\n",
            "\n",
            "    accuracy                           0.81      4500\n",
            "   macro avg       0.76      0.60      0.62      4500\n",
            "weighted avg       0.79      0.81      0.77      4500\n",
            "\n",
            "Accuracy : 0.8077777777777778\n",
            "Precision: 0.6966966966966966\n",
            "Recall   : 0.23293172690763053\n",
            "F1-Score : 0.3491346877351392\n",
            "ROC-AUC  : 0.7170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 6: Initial Random Forest Model (Default Parameters)\n",
        "# ==========================================\n",
        "\n",
        "rf_base = RandomForestClassifier(random_state=42) #önce default parametrelerle base olarak random forest yaparız\n",
        "rf_base.fit(X_train_s, y_train)\n",
        "\n",
        "# Validation set üzerinde performans (tuning öncesi referans)\n",
        "y_val_prob_base = rf_base.predict_proba(X_val_s)[:, 1] #sadece roc auc için olan predicti yapıyoruz\n",
        "auc_rf_base_val = roc_auc_score(y_val, y_val_prob_base) #roc-auc hesaplama\n",
        "\n",
        "print(f\"\\nInitial Random Forest – Validation ROC-AUC: {auc_rf_base_val:.4f}\")\n",
        "#Tune edilmemiş halinde bile random forest (0.75) logistic regresiondan (0.71) daha iyi\n",
        "#çünkü non linear patternları random forest daha iyi öğreniyor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1O0byP_OsiD",
        "outputId": "947b7a71-873f-45b4-859c-38dc865cbb67"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial Random Forest – Validation ROC-AUC: 0.7571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 7  Tuning\n",
        "# ==========================================\n",
        "\n",
        "# Train + Validation birleştiriyoruz hangisinin train hangisin val dataları olduğunu belirteceğiz\n",
        "X_train_val_s = np.vstack([X_train_s, X_val_s]) #x_train_val_s değişkeninde hem train hem val datalarını birleştirdik\n",
        "y_train_val   = np.concatenate([y_train, y_val]) #y nin train validate datalarını da birleştirdik\n",
        "\n",
        "#default k-fold-cross validation yapmaması için bizim istediğimiz gibi yüzde 15le validation yapması için:\n",
        "##train veri sayısı kadar -1 validation veri sayısı kadar 0 yazdık\n",
        "test_fold = np.array([-1] * len(X_train_s) + [0] * len(X_val_s))\n",
        "ps = PredefinedSplit(test_fold)\n",
        "# PredefinedSplit: -1 olan indeksleri train, 0 olan indeksleri validation olarak kabul eden bir split objesi oluşturur.\n",
        "\n",
        "\n",
        "# proje dosyasındaji parametreleri dictionary içinde veriyoruz\n",
        "param_dist = {\n",
        "    \"n_estimators\": [100, 200, 300, 500], #4 farklı ağaç sayısı belirleyip hepsini tek tek deneyip en iyisini seç\n",
        "    \"max_depth\": [None, 5, 10, 15, 20], #5 farklı ağaç derinliği sayısıyla dene bir tanesi sınırsız derinlik\n",
        "    \"max_features\": [\"sqrt\", \"log2\", 0.5],\n",
        "#split yaparken featureler arasında impurity hesaplaması yapar her bir splitte kaç zaten feature arasından feature seçeceğini belirler\n",
        "#her splite verilecek feature sayısı için: birinde toplam featurenin karekökü kadar birinde log2si kadar birinde de yarısı kadar\n",
        "#model elde kalan featureler üzerinden random bir şekilde bukadar feature seçer\n",
        "#elde kalan feature sayısı burada kalan kadar yoksa kalan kadar feature seçilir\n",
        "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
        "#Leaf node’un içindeki örneklerin çoğunluğu hangi sınıftaysa, model o sınıfı output verir.\n",
        "#her bir ağacın leaf node'unda minimum kaç kişi olması gerektiği\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)#boş eğitimsiz bir model daha oluşturduk\n",
        "\n",
        "rf_search = RandomizedSearchCV(  #tuning\n",
        "    estimator=rf, #tuning yapılacak model\n",
        "    param_distributions=param_dist, #yukarıda oluşturduğumuz parametre kurallarını verdik\n",
        "    n_iter=20, #toplam 20 farklı parametre kombinasyonunu dene\n",
        "    scoring=\"roc_auc\", #hani kombinasyonda roc auc en yüksekse onu seç\n",
        "    cv=ps, #cross-validationu kendi 15 15 bölerek yukarıda yaptığımı burada verdim\n",
        "    random_state=42,\n",
        "    n_jobs=-1, #tüm cpu çekirdeklerini kullan\n",
        "    verbose=1 #\n",
        ")\n",
        "\n",
        "rf_search.fit(X_train_val_s, y_train_val) #tuningi başlattık\n",
        "\n",
        "print(\"\\nBest Parameters from RandomizedSearchCV:\")\n",
        "print(rf_search.best_params_) #RandomizedSearch ün içinde best_paramsda en iyi parametre kombinasyonu tutulur\n",
        "print(f\"Best Validation ROC-AUC: {rf_search.best_score_:}\") #tuningden sonra best roc auc 0.7750 çıktı başta 0.75di\n",
        "\n",
        "# best_estimator_ train+val üzerinde yeniden eğitilmiş durumdadır\n",
        "best_rf = rf_search.best_estimator_ #hyperparameter'ı optimize edilmiş travin validation verisiyle eğitilmiş tahmin yapmaya hazır nihai model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc3y1PG0OvqG",
        "outputId": "da0cd473-e939-4b3d-a693-b33cb10193d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 8: Final Random Forest Test Performance\n",
        "# ==========================================\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test_s) #1 ve 0 lardan oluşan tahmin çıktıları\n",
        "y_prob_rf = best_rf.predict_proba(X_test_s)[:, 1] #1 in ve 0 ın ihtimallerinden oluştan tahmin çıktıları\n",
        "\n",
        "acc_rf  = accuracy_score(y_test, y_pred_rf)\n",
        "prec_rf = precision_score(y_test, y_pred_rf)\n",
        "rec_rf  = recall_score(y_test, y_pred_rf)\n",
        "f1_rf   = f1_score(y_test, y_pred_rf)\n",
        "auc_rf  = roc_auc_score(y_test, y_prob_rf)\n",
        "\n",
        "print(\"\\n=== Random Forest (Tuned) – Test Performance ===\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(f\"Accuracy : {acc_rf:}\")\n",
        "print(f\"Precision: {prec_rf:}\")\n",
        "print(f\"Recall   : {rec_rf:}\")\n",
        "print(f\"F1-Score : {f1_rf:}\")\n",
        "print(f\"ROC-AUC  : {auc_rf:.4f}\")\n"
      ],
      "metadata": {
        "id": "q7qM3kquOzWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 9 Comparison\n",
        "# ==========================================\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Logistic Regression\", \"Random Forest (Tuned)\"],\n",
        "    \"Accuracy\": [acc_log, acc_rf],\n",
        "    \"Precision\": [prec_log, prec_rf],\n",
        "    \"Recall\": [rec_log, rec_rf],\n",
        "    \"F1-Score\": [f1_log, f1_rf],\n",
        "    \"ROC-AUC\": [auc_log, auc_rf]\n",
        "})\n",
        "\n",
        "print(\"\\nPerformance Comparison Table:\")\n",
        "print(results)\n",
        "#Accuracy:random forest non linear öğrenebildiği için doğruluğu daha iyi ama yine de küçük bir fark var. #imbalanced datasete yetersiz bir metric\n",
        "#Precision:Logistic reg daha iyi. Bu logistic regin daha temkinli yaklaşmasından olabilir yani daha az kişiye default edecek der o yüzden daha sık haklı çıkıyor\n",
        "#     yani yanlış alarm daha çok ödemeyecek dedik ama kişi ödemiş.\n",
        "#     Bankacılık sisteminde yanlış alarmın fazla olması banka açısından faydalı olabilir daha sık bir elemeden geçirir\n",
        "#     Bir yandan da iyi müşteriler reddedilip kar ihtimali de düşebilir\n",
        "#     Random forest daha agresif davranıp daha çok kişiye default diyor o yüzden kesinliği biraz düşük çıkmış\n",
        "#Recall: Gerçek ödemeyecek kişilerin yakalanma oranında ikisi de düşük ama random forest belirgin bir şekilde daha yüksek\n",
        "#F1-Score:pre rec harmonik ortalaması random forest anlamlı bir şekilde daha yüksek\n",
        "#Roc-auc:imbalanced datasetlerde en önemli metriclerdendir ve random forest anlamlı bir şekilde daha yüksektir\n",
        "#genel olarak random forestın daha iyi olmasını nonlinear patternları daha iyi anlamasına bağlayabiliriz"
      ],
      "metadata": {
        "id": "KgPUbnuzO2cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 10  ROC Curve Comparison\n",
        "# ==========================================\n",
        "\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)\n",
        "fpr_rf,  tpr_rf,  _ = roc_curve(y_test, y_prob_rf)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.plot(fpr_log, tpr_log, label=f\"Logistic Regression (AUC = {auc_log:.3f})\")\n",
        "plt.plot(fpr_rf,  tpr_rf,  label=f\"Random Forest (AUC = {auc_rf:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#genel olarak random forest sınıfları (default non default) daha iyi ayırır"
      ],
      "metadata": {
        "id": "93Buh2CaO4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 11 Precision–Recall Curve Comparison\n",
        "# ==========================================\n",
        "\n",
        "prec_log_curve, rec_log_curve, _ = precision_recall_curve(y_test, y_prob_log)\n",
        "prec_rf_curve,  rec_rf_curve,  _ = precision_recall_curve(y_test, y_prob_rf)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.plot(rec_log_curve, prec_log_curve, label=\"Logistic Regression\")\n",
        "plt.plot(rec_rf_curve,  prec_rf_curve,  label=\"Random Forest\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curve Comparison\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#yine random forestın daha iyi olduğu gözükür"
      ],
      "metadata": {
        "id": "iajO8vnGO63C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# Step 12: Feature Importance Analysis\n",
        "# ==========================================\n",
        "\n",
        "importances = best_rf.feature_importances_  #\n",
        "feat_imp = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nTop Featuress' Importance\")\n",
        "print(feat_imp.head(23))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "feat_imp.head(23).plot(kind=\"bar\")\n",
        "plt.title(\"Features' Importances (Random Forest)\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vX3i0t6hO9Pg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}